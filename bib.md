> A short list of some related papers.

### Hankel completion

 1. [Fast Hankel Tensor-Vector Products and Application to Exponential Data Fitting](https://arxiv.org/pdf/1401.6238.pdf). arXiv preprint, 2014.
 2. [Fast and provable algorithms for spectrally sparse signal reconstruction via low-rank Hankel matrix completion](http://dx.doi.org/10.1016/j.acha.2017.04.004). Applied and Computational Harmonic Analysis, 2017.
 3. [Hankel Matrix Nuclear Norm Regularized Tensor Completion for N-dimensional Exponential Signals](https://doi.org/10.1109/TSP.2017.2695566). IEEE Transactions on Signal Processing, 2017. 
 4. [Missing Slice Recovery for Tensors Using a Low-rank Model in Embedded Space](https://openaccess.thecvf.com/content_cvpr_2018/papers/Yokota_Missing_Slice_Recovery_CVPR_2018_paper.pdf). CVPR 2018.
 5. [Correction of Corrupted Columns Through Fast Robust Hankel Matrix Completion](https://doi.org/10.1109/TSP.2019.2904021). IEEE Transactions on Signal Processing, 2019.
 6. [Block Hankel Tensor ARIMA for Multiple Short Time Series Forecasting](https://arxiv.org/pdf/2002.12135.pdf). AAAI 2020.
 7. [Matrix and Tensor Completion in Multiway Delay Embedded Space Using Tensor Train, With Application to Signal Reconstruction](https://doi.org/10.1109/LSP.2020.2990313). IEEE Signal Processing Letters, 2020.
 8. [Structured Gradient Descent for Fast Robust Low-Rank Hankel Matrix Completion](https://arxiv.org/abs/2204.03316). arXiv preprint, 2022.
 9. [Fast Algorithm for Low-rank Tensor Completion in Delay-embedded Space](https://openaccess.thecvf.com/content/CVPR2022/papers/Yamamoto_Fast_Algorithm_for_Low-Rank_Tensor_Completion_in_Delay-Embedded_Space_CVPR_2022_paper.pdf). CVPR 2022.
 10. [Hankel low-rank approximation and completion in time series analysis and forecasting: a brief review](https://hal.archives-ouvertes.fr/hal-03690201/document).  Statistics and Its Interface, 2022.

### Deep prior

 1. [Deep image prior](https://dmitryulyanov.github.io/deep_image_prior)
 2. [On the Connection Between Learning Two-Layer Neural Networks and Tensor Decomposition](http://proceedings.mlr.press/v89/mondelli19a/mondelli19a.pdf). ICML 2019.
 3. [Implicit Regularization in Deep Matrix Factorization](https://papers.nips.cc/paper/2019/file/c0c783b5fc0d7d808f1d14a6e9c8280d-Paper.pdf). NeurIPS 2019. [[Python code](https://github.com/roosephu/deep_matrix_factorization)]
 4. [Understanding implicit regularization in deep learning by analyzing trajectories of gradient descent](http://www.offconvex.org/2019/07/10/trajectories-linear-nets/), 2019.
 5. [Can implicit regularization in deep learning be explained by norms?](http://www.offconvex.org/2020/11/27/reg_dl_not_norm/) 2020.
 6. [Implicit Regularization in Tensor Factorization: Can Tensor Rank Shed Light on Generalization in Deep Learning?](http://www.offconvex.org/2021/07/08/imp-reg-tf/) 2021.
 7. [Implicit Regularization in Tensor Factorization](https://arxiv.org/pdf/2102.09972.pdf). arXiv preprint, 2021.
 8. [Compressive Spectral Image Reconstruction using Deep Prior and Low-Rank Tensor Representation](https://arxiv.org/pdf/2101.07424.pdf). arXiv preprint, 2021.
 9. [DeepTensor: Low-Rank Tensor Decomposition with Deep Network Priors](https://arxiv.org/pdf/2204.03145.pdf). arXiv preprint, 2022.
 10. [Implicit Regularization in Hierarchical Tensor Factorization and Deep Convolutional Neural Networks](https://arxiv.org/pdf/2201.11729.pdf). ICML 2022.

### Irregularly-sampled time series

 1. [Learning from Irregularly-Sampled Time Series: A Missing Data Perspective](https://arxiv.org/pdf/2008.07599.pdf). arXiv preprint, 2020.
